{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring directories\n",
    "train_dir=\"\" #example file path: /content/drive/TrainingImages\n",
    "test_dir=\"\"\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "x_test=[]\n",
    "y_test=[]\n",
    "\n",
    "#loading training images from training directory\n",
    "for class_name in os.listdir(train_dir):\n",
    "    class_path = os.path.join(train_dir, class_name)\n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = img/255.0\n",
    "        x.append(img)\n",
    "        y.append(class_name)\n",
    "\n",
    "#loading test images from test directory\n",
    "for class_name in os.listdir(test_dir):\n",
    "    class_path = os.path.join(test_dir, class_name)\n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = img/255.0\n",
    "        x_test.append(img)\n",
    "        y_test.append(class_name)\n",
    "\n",
    "#Converting into a numpy array\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "x_test=np.array(x_test)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing library for feature extraction using scikit-image HOG\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Extracting HOG features from the RGB images for training and test data set\n",
    "hog_features = []\n",
    "hog_features_test=[]\n",
    "\n",
    "for image in x:\n",
    "    # Computing HOG features for each image\n",
    "    features = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), transform_sqrt=True,channel_axis=-1)\n",
    "    hog_features.append(features)\n",
    "\n",
    "for image in x_test:\n",
    "    features_test = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), transform_sqrt=True,channel_axis=-1)\n",
    "    hog_features_test.append(features_test)\n",
    "\n",
    "# Converting hog_features to a NumPy array\n",
    "hog_features = np.array(hog_features)\n",
    "hog_features_test=np.array(hog_features_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example to visualize the working of HOG feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "#loading an image from training dataset\n",
    "image=x[3]\n",
    "# Extracting HOG features\n",
    "fd, hog_image = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 1), visualize=True, channel_axis=-1)\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "# PLotting the images for comparision\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "ax1.imshow(image)\n",
    "ax1.set_title(y[3])\n",
    "ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "ax2.set_title('HOG Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into training and validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(hog_features,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing svm using various kernels \n",
    "rbf = svm.SVC(kernel='rbf', gamma='scale', C=1.0,decision_function_shape='ovr').fit(x_train, y_train)\n",
    "poly = svm.SVC(kernel='poly', degree=3, C=1,decision_function_shape='ovr').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy and F1 scores for validaiton and test data usign rbf\n",
    "rbf_predict=rbf.predict(x_val)\n",
    "rbf_predict_test=rbf.predict(hog_features_test)\n",
    "\n",
    "rbf_accuracy = accuracy_score(y_val, rbf_predict)\n",
    "rbf_test_accuracy=accuracy_score(y_test,rbf_predict_test)\n",
    "\n",
    "rbf_f1 = f1_score(y_val, rbf_predict, average='weighted')\n",
    "rbf_f1_test = f1_score(y_test, rbf_predict_test, average='weighted')\n",
    "\n",
    "print('Accuracy (RBF Kernel): ', \"%.2f\" % (rbf_accuracy*100))\n",
    "print('F1 (RBF Kernel): ', \"%.2f\" % (rbf_f1*100))\n",
    "\n",
    "print('Test Accuracy (RBF Kernel): ', \"%.2f\" % (rbf_test_accuracy*100))\n",
    "print('F1 (RBF Kernel) value for test data: ', \"%.2f\" % (rbf_f1_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy and F1 scores for validaiton and test data usign poly\n",
    "poly_predict=poly.predict(x_val)\n",
    "poly_predict_test=poly.predict(hog_features_test)\n",
    "\n",
    "poly_accuracy = accuracy_score(y_val, poly_predict)\n",
    "poly_accuracy_test = accuracy_score(y_test, poly_predict_test)\n",
    " \n",
    "poly_f1 = f1_score(y_val, poly_predict, average='weighted')\n",
    "poly_f1_test = f1_score(y_test, poly_predict_test, average='weighted')\n",
    "\n",
    "\n",
    "print('Accuracy (Polynomial Kernel): ', \"%.2f\" % (poly_accuracy*100))\n",
    "print('F1 (Polynomial Kernel): ', \"%.2f\" % (poly_f1*100))\n",
    "\n",
    "print('Test Accuracy (Polynomial Kernel): ', \"%.2f\" % (poly_accuracy_test*100))\n",
    "print('F1 (Polynomial Kernel) value for test data: ', \"%.2f\" % (poly_f1_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_test, rbf_predict_test)\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "ax.set(xticks=np.arange(cm.shape[1]),\n",
    "       yticks=np.arange(cm.shape[0]),\n",
    "       xlabel='Predicted label',\n",
    "       ylabel='True label',\n",
    "       title='Confusion Matrix for SVM Multiclass Image Classification')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using **KNN** for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing dimensionality reduction using PCA\n",
    "pca = PCA(n_components=2)\n",
    "x_train_pca= pca.fit_transform(x_train)\n",
    "x_val_pca=pca.fit_transform(x_val)\n",
    "x_test_pca=pca.fit_transform(hog_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter plot for the data\n",
    "import pandas as pd\n",
    "columns=['col1','col2']\n",
    "df=pd.DataFrame(x_train_pca,columns=columns)\n",
    "cmap=plt.cm.get_cmap('coolwarm')\n",
    "plt.scatter(df['col1'],df['col2'],c=df['col1'],cmap=cmap)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up for GridSearchCV\n",
    "knn=KNeighborsClassifier()\n",
    "grid_parameters={'n_neighbors':[4,8,16,36,72],'metric':['euclidean','manhattan','cosine']}\n",
    "grid_search = GridSearchCV(knn,grid_parameters,cv=5)\n",
    "grid_search.fit(x_train_pca,y_train)\n",
    "best_neigbors=grid_search.best_params_['n_neighbors']\n",
    "best_metric=grid_search.best_params_['metric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the KNN model\n",
    "knn_model=KNeighborsClassifier(n_neighbors=best_neigbors,metric=best_metric)\n",
    "knn_model.fit(x_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the optimal parameters\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "#Printing the results for validation data\n",
    "y_pred = knn_model.predict(x_val_pca)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Validation Accuracy: \", accuracy*100)\n",
    "#Printing the results for testing data\n",
    "y_pred_test=knn_model.predict(x_test_pca)\n",
    "accuracy=accuracy_score(y_pred_test,y_test)\n",
    "print(\"Testing Accuracy: \",accuracy*100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random_Forest_Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the RFC library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#training the RFC model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(x_train,y_train)\n",
    "#predicting the validation and test data\n",
    "y_val_pred1=rf.predict(x_val)\n",
    "y_val_pred2=rf.predict(hog_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the accuracy results\n",
    "ac1=accuracy_score(y_val,y_val_pred1)\n",
    "ac2=accuracy_score(y_val_pred2,y_test)\n",
    "print(\"Validation Accuracy: \",ac1*100,\" Test Accuracy: \",ac2*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
